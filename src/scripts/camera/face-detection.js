import { drawLandmarks } from '/scripts/face-api/face_landmark-draw.js';
import { displayFaceStatus, showGuidingArrow } from '../utils/utils.js';
import { showDirectionArrow } from './direction-arrow.js';
import {updateFeedbackImage} from './direction-image.js';

let isProcessing = false;
let frontalCount = 0;
const frontalThreshold = 3;

let prevFeedback = '';

export async function startFaceDetection(videoElement) {
  const canvas = document.getElementById('overlay');
  const context = canvas.getContext('2d', { willReadFrequently: true });
  canvas.width = videoElement.videoWidth;
  canvas.height = videoElement.videoHeight;

  async function loop() {
    const detections = await faceapi
      .detectAllFaces(videoElement)
      .withFaceLandmarks()
      .withFaceDescriptors();

    const resizedDetections = faceapi.resizeResults(detections, {
      width: canvas.width,
      height: canvas.height,
    });

    context.clearRect(0, 0, canvas.width, canvas.height);
    context.setTransform(-1, 0, 0, 1, canvas.width, 0); // ì¢Œìš° ë°˜ì „

    if (resizedDetections.length > 0 && !isProcessing) {
      isProcessing = true;

      const face = resizedDetections[0];
      drawLandmarks(context, face.landmarks.positions); // í•­ìƒ ë§ˆì  íƒ€

/*    const faceImage = cropFace(videoElement, face.detection.box);
      const blob = await new Promise(resolve =>
        faceImage.toBlob(resolve, 'image/jpeg')
      ); */
      const canvasFull = document.createElement('canvas');
      canvasFull.width = videoElement.videoWidth;
      canvasFull.height = videoElement.videoHeight;
      const ctxFull = canvasFull.getContext('2d');
      ctxFull.drawImage(videoElement, 0, 0, canvasFull.width, canvasFull.height);
      const blob = await new Promise(resolve =>
        canvasFull.toBlob(resolve, 'image/jpeg')
      );


      const formData = new FormData();
      formData.append('file', blob, 'face.jpg');

      try {
        const response = await fetch('http://127.0.0.1:8000/detect-face', {
          method: 'POST',
          body: formData,
        });
        const result = await response.json();

        // ê¸°ì¤€ ì ìš©
        const isStableSlope = result.slope_horizontal > -0.015 && result.slope_horizontal < 0.015;
        const isStableArea = result.area_ratio_diff <= 0.08;

        let trulyFrontal = false;
        if (isStableSlope && isStableArea) {
          frontalCount++;
          if (frontalCount >= frontalThreshold) {
            trulyFrontal = true;
          }
        } else {
          frontalCount = 0;
        }

        // í”¼ë“œë°± íŒë‹¨
        let feedback = "ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤";
        let direction = null;
        let feedbackImage = null;
        if (!trulyFrontal) {
          if (result.tilt_direction === 'Left') {
            feedback = 'ê³ ê°œë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ìš¸ì—¬ì£¼ì„¸ìš”';
            direction = 'down_right'
            feedbackImage = 'slope';
          } else if (result.tilt_direction === 'Right') {
            feedback = 'ê³ ê°œë¥¼ ì™¼ìª½ìœ¼ë¡œ ê¸°ìš¸ì—¬ì£¼ì„¸ìš”';
            direction = 'down_left'
            feedbackImage = 'slope';
          } else if (result.tilt_direction === 'area_Left'){
            feedback = `ê³ ê°œë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒë ¤ì£¼ì„¸ìš”`;
            direction = 'right'
            feedbackImage = 'area';
          } else if (result.tilt_direction === 'area_Right'){
            feedback = `ê³ ê°œë¥¼ ì™¼ìª½ìœ¼ë¡œ ëŒë ¤ì£¼ì„¸ìš”`;
            direction = 'left'
            feedbackImage = 'area';
          }
          else if (result.tilt_direction === 'Frontal'){
            feedback = "ì •ë©´ ì¸ì‹ ì™„ë£Œ"
            direction = null;
          }
        }

        // í”¼ë“œë°±ì´ ë°”ë€Œì—ˆì„ ë•Œë§Œ ì—…ë°ì´íŠ¸
        if (feedback !== prevFeedback) {
          displayFaceStatus(feedback);
          showGuidingArrow(feedback === 'ì •ë©´ ì¸ì‹ë¨' ? null : result.tilt_direction);
          showDirectionArrow(direction);
          updateFeedbackImage(feedbackImage);
          prevFeedback = feedback;
        }

        console.log("ğŸ§­ ì •ë©´ íŒë³„ ë¡œê·¸:", result);
      } catch (err) {
        console.error('ì„œë²„ í†µì‹  ì˜¤ë¥˜:', err);
      }

      isProcessing = false;
    }

    context.setTransform(1, 0, 0, 1, 0, 0); // ì›ìƒë³µêµ¬
    requestAnimationFrame(loop);
  }

  loop();
}

function cropFace(video, box) {
  const canvas = document.createElement('canvas');
  canvas.width = box.width;
  canvas.height = box.height;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(video, box.x, box.y, box.width, box.height, 0, 0, box.width, box.height);
  return canvas;
}